---
title: "Tweets während der Konstituierung des 19.Bundestages"
#author: "Franziska Löw"
date: "`r format(Sys.Date())`"
output: github_document
---

```{r, include=FALSE}
# load the packages
libs <- c("tidytext","tidyr","readr","lubridate","tm","stm",
          "plyr","dplyr","class","knitr",'network', 'sna',
          "htmlTable","ggplot2","gridExtra","jsonlite","stringr","scales")
lapply(libs, library, character.only = TRUE)
```

```{r, include=FALSE}
rm(list = ls())
load(file = "../../politsentiment_data/out/tweets_jamaika.Rda")

col <- c("deepskyblue1", "black","limegreen", "darkorchid2","gold","grey", "red2")
names(col) <- levels(tweets$partei)
```

```{r}
# get the tweets that are retweeted 
tweets$isretweet <- ifelse(grepl('^RT', tweets$text),TRUE,FALSE)

tweets %>%
  filter(lang=="en") -> tweets_en

tweets %>%
  filter(lang=="de") -> tweets
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# Extract the retweets
tweets %>%
  distinct(text,name, .keep_all = TRUE) %>%
  filter(isretweet == TRUE) -> rt

tweets_en %>%
  distinct(text,name, .keep_all = TRUE) %>%
  filter(isretweet == TRUE) -> rt_en

# pull the original author's name
rt$sender <- substr(rt$text, 5, regexpr(':', rt$text) - 1)
rt_en$sender <- substr(rt_en$text, 5, regexpr(':', rt_en$text) - 1)

# Extract the retweets
orig <-  tweets[which(tweets$isretweet==FALSE),]
orig_en <-  tweets_en[which(tweets_en$isretweet==FALSE),]
```

### Zeitraum

```{r, echo=FALSE, message=FALSE, warning=FALSE}
ggplot(tweets, aes(date, fill=partei)) + 
    geom_histogram(alpha = .8, adjust = .25, 
                   binwidth = 500) +
    scale_fill_manual(name = "", values = col) +
    xlab("") +
    ylab("Anzahl der Tweets") +
    scale_x_datetime(breaks = date_breaks("6 hour"), labels=date_format("%d.%m\n%H:%M", tz="CET"))
```

## Wer retweeted wen?

```{r, echo=FALSE, message=FALSE, warning=FALSE}
col3 = RColorBrewer::brewer.pal(3, 'Paired')

# Adjust retweets to create an edgelist for network
el <- as.data.frame(cbind(sender = tolower(rt$sender), 
                         receiver = tolower(rt$name)))
el <- count(el, sender, receiver) 
el <- el[which(el$n>2),]
el <- el[which(nchar(as.character(el$sender))>0),]
el <- el[which(nchar(as.character(el$receiver))>0),]

rtnet <- network(el, directed = TRUE, matrix.type = 'edgelist',
                ignore.eval = FALSE, names.eval = 'num')

# Get names of only those who were retweeted to keep labeling reasonable
vlabs <- rtnet %v% 'vertex.names'
vlabs[degree(rtnet, cmode = 'outdegree') < 15] = NA

par(mar = c(0, 0, 3, 0))
plot(rtnet, label = vlabs, label.col = "blue",
     label.pos = 5, label.cex = .8, 
     vertex.cex = log(degree(rtnet)) + .5, vertex.col = "gray",
     edge.lwd = 'num', edge.col = col3[3], main = '')
```

### Welche Tweets wurden am häufigsten Retweeted?

```{r, echo=FALSE, message=FALSE, warning=FALSE}
orig$retweet_count <- as.numeric(orig$retweet_count)

orig %>%
  distinct(text, .keep_all = TRUE) %>%
  arrange(desc(retweet_count)) %>%
  select(name, text, retweet_count) %>%
  .[1:10,] %>%
  htmlTable::htmlTable(align = "l")
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
orig_en$retweet_count <- as.numeric(orig_en$retweet_count)

orig_en %>%
  distinct(text, .keep_all = TRUE) %>%
  arrange(desc(retweet_count)) %>%
  select(name, text, retweet_count) %>%
  .[1:10,] %>%
  htmlTable::htmlTable(align = "l")
```

## Über welche Partei wird am meisten getweeted?

Anzahlt gesamte Tweets (ohne Retweets):
```{r, echo=FALSE}
nrow(orig)
```

```{r, echo=FALSE}
orig %>%
  filter(!partei=="None") %>%
  ggplot(aes(partei))+
  geom_bar(fill = c("deepskyblue1", "black","limegreen", "darkorchid2","gold","red2"), alpha = .8) +
  xlab("")+
  coord_flip()
```

Wie sieht das bei englisch sprachigen Tweets aus? Hier ist die Anzahlt der gesamten Tweets (ohne Retweets):
```{r, echo=FALSE}
nrow(orig_en)
```

```{r, echo=FALSE}
orig_en %>%
  filter(!partei=="None") %>%
  ggplot(aes(partei))+
  geom_bar(fill = c("deepskyblue1", "black","limegreen", "darkorchid2","gold","red2"), alpha = .8) +
  xlab("")+
  coord_flip()
```

## Term frequency

### Wordclouds

... nach Parteinennung

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(wordcloud)
# WordClouds ####
# get text
cdu <- orig[which(orig$partei=="CDU"),]
spd <- orig[which(orig$partei=="SPD"),]
fdp <- orig[which(orig$partei=="FDP"),]
gruene <- orig[which(orig$partei=="Die Grünen"),]
linke <- orig[which(orig$partei=="DIE LINKE"),]
afd <- orig[which(orig$partei=="AfD"),]

# Join texts in a vector 
cdu <- paste(cdu$text_cleaned, collapse = " ")
spd <- paste(spd$text_cleaned, collapse = " ")
fdp <- paste(fdp$text_cleaned, collapse = " ")
gruene <- paste(gruene$text_cleaned, collapse = " ")
linke <- paste(linke$text_cleaned, collapse = " ")
afd <- paste(afd$text_cleaned, collapse = " ")

# put everything in a single vector
all <- c(cdu, spd, fdp,gruene, linke, afd)

ignore <- paste(c("cdu","bündnis", "spd","fdp","gruene","grüne","grünen", "linke","dielinke","afd","gen","merkel","schulz","csu","union"), collapse = "|")
all <- gsub(ignore,"", all)

# Step 2: Corpus and term-docs_cleaned matrix ####
# create corpus
corp <- Corpus(VectorSource(all))

# create term-docs_cleaned matrix
tdm <- TermDocumentMatrix(corp)

# convert as matrix
tdm <- as.matrix(tdm)

# add column names
colnames(tdm) <- c("CDU","SPD","FDP","Die Grünen", "DIE LINKE","AfD")

# Step 3: Plot comparison wordcloud ####
comparison.cloud(tdm, random.order=FALSE, colors = c("black","red2", "gold","limegreen", "darkorchid2","deepskyblue1"), scale=c(3,.5),
                 title.size=.8, max.words=150)
```

...gesamte deutsche Tweets

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# get text
#none <- orig[which(orig$partei=="None"),]

# Join texts in a vector 
none <- paste(orig$text_cleaned, collapse = " ")

#ignore <- paste(c("jamaika","the"), collapse = "|")
#none <- gsub(ignore,"", none)

# Step 2: Corpus and term-docs_cleaned matrix ####
# create corpus
corp <- Corpus(VectorSource(none))

# create term-docs_cleaned matrix
tdm <- TermDocumentMatrix(corp)
# convert to matrix
tdm.m <- as.matrix(tdm)

ap.v <- sort(rowSums(tdm.m),decreasing=TRUE)
ap.d <- data.frame(word = names(ap.v),freq=ap.v)

# Plot Wordcloud
pal2 <- brewer.pal(8,"Dark2")
wordcloud(ap.d$word,ap.d$freq, min.freq=30,
max.words=Inf, random.order=FALSE, rot.per=.15, colors=pal2)
```

...englische Tweets
```{r, echo=FALSE, message=FALSE, warning=FALSE}
# Join texts in a vector 
engl <- paste(orig_en$text_cleaned, collapse = " ")

engl <- removeWords(engl,stopwords("en"))

# Step 2: Corpus and term-docs_cleaned matrix ####
# create corpus
corp <- Corpus(VectorSource(engl))

# create term-docs_cleaned matrix
tdm <- TermDocumentMatrix(corp)
# convert to matrix
tdm.m <- as.matrix(tdm)

ap.v <- sort(rowSums(tdm.m),decreasing=TRUE)
ap.d <- data.frame(word = names(ap.v),freq=ap.v)

# Plot Wordcloud
pal2 <- brewer.pal(8,"Dark2")
wordcloud(ap.d$word,ap.d$freq, min.freq=5,
max.words=Inf, random.order=FALSE, rot.per=.15, colors=pal2)
```

### inverse document frequency (tf-idf)
 
```{r, include=FALSE}
token <- orig %>%
  group_by(partei) %>%
  unnest_tokens(word, text_cleaned) %>%
  count(partei, word, sort = TRUE)  %>%
  bind_tf_idf(word, partei, n) %>%
  arrange(desc(tf_idf))
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
ignore <- c("afd", "cdu","spd","fdp","linke","linken","dielinke","gruene", "grüne","grünen", "merkel","schulz","lindner","union","wagenknecht","sahra")

plot_tweets <- token %>%
  arrange(desc(tf_idf)) %>%
  mutate(word = factor(word, levels = rev(unique(word))))

plot_tweets %>% 
  filter(!word %in% ignore) %>%
  top_n(5) %>%
  ggplot(aes(reorder(word, tf_idf), tf_idf, fill = partei)) +
  geom_col(alpha = .9, show.legend = FALSE) +
  scale_fill_manual(name="", values=col) +
  labs(x = NULL, y = "tf-idf") +
      #facet_wrap(~partei, ncol = 2, scales = "free") +
  coord_flip()
```

## Sentiment Analyse

```{r, message=FALSE, warning=FALSE, include=FALSE}
# Load dictionaries (from: http://wortschatz.uni-leipzig.de/de/download)
neg_df <- read_tsv("../dict/SentiWS_v1.8c_Negative.txt", col_names = FALSE)
names(neg_df) <- c("Wort_POS", "Wert", "Inflektionen")

neg_df %>% 
  mutate(Wort = str_sub(Wort_POS, 1, regexpr("\\|", .$Wort_POS)-1),
         POS = str_sub(Wort_POS, start = regexpr("\\|", .$Wort_POS)+1)) -> neg_df


pos_df <- read_tsv("../dict/SentiWS_v1.8c_Positive.txt", col_names = FALSE)
names(pos_df) <- c("Wort_POS", "Wert", "Inflektionen")

pos_df %>% 
  mutate(Wort = str_sub(Wort_POS, 1, regexpr("\\|", .$Wort_POS)-1),
         POS = str_sub(Wort_POS, start = regexpr("\\|", .$Wort_POS)+1)) -> pos_df

bind_rows("neg" = neg_df, "pos" = pos_df, .id = "neg_pos") -> sentiment_df

sentiment_df %>% select(neg_pos, Wort, Wert, Inflektionen, -Wort_POS) -> sentiment_df

sentiment_df %>% 
  rename(word = Wort) -> sentiment_df
```

```{r, message=FALSE, warning=FALSE, include=FALSE}
token <- orig %>%
  unnest_tokens(word, text_cleaned)

sentiment_neg <- match(token$word, filter(sentiment_df, neg_pos == "neg")$word)
sentiment_pos <- match(token$word, filter(sentiment_df, neg_pos == "pos")$word)

token %>% 
  mutate(sentiment_neg = sentiment_neg,
         sentiment_pos = sentiment_pos) -> token

token %>%
  group_by(partei, word) %>%
  mutate(count = n()) -> token

token %>%
  group_by(partei) %>%
  filter(!is.na(sentiment_neg)) %>%
  dplyr::select(word, count) -> negative_sentiments

token %>%
  group_by(partei) %>%
  filter(!is.na(sentiment_pos)) %>%
  dplyr::select(word, count) -> positive_sentiments
```

#### Anzahl negativer Sentiment-Wörter

```{r, echo=FALSE, message=FALSE, warning=FALSE}
plot_sentiments <- negative_sentiments %>%
  arrange(desc(count)) %>%
  group_by(partei) %>%
  distinct() %>%
  mutate(word = factor(word, levels = rev(unique(word))))

plot_sentiments %>% 
  top_n(3) %>%
  ggplot(aes(reorder(word, count), count, fill = partei)) +
  geom_col(alpha = .8, show.legend = FALSE) +
  scale_fill_manual(values=col) +
  labs(x = NULL, y = "negative term count") +
  coord_flip()
```

#### Anzahl positiver Sentiment-Wörter

```{r, echo=FALSE, message=FALSE, warning=FALSE}
plot_sentiments <- positive_sentiments %>%
  arrange(desc(count)) %>%
  group_by(partei) %>%
  distinct() %>%
  mutate(word = factor(word, levels = rev(unique(word))))

plot_sentiments %>% 
  top_n(8) %>%
  ggplot(aes(reorder(word, count), count, fill = partei)) +
  geom_col(alpha = .9, show.legend = FALSE) +
  scale_fill_manual(values=col) +
  labs(x = NULL, y = "positive term count") +
     # facet_wrap(~partei, ncol = 2, scales = "free") +
  coord_flip()
```

### Gewichtete Analyse

```{r, echo=FALSE, message=FALSE, warning=FALSE}
token %>% 
  left_join(sentiment_df, by = "word") -> token 

token %>% 
  group_by(partei) %>%
  filter(!partei=="None") %>%
  filter(!is.na(Wert)) %>% 
  summarise(Sentimentwert = sum(Wert, na.rm = TRUE)) %>%
  ggplot(aes(reorder(partei,Sentimentwert), Sentimentwert)) +
          xlab("") +
           geom_col(fill = c("gold","limegreen","red2","darkorchid2","deepskyblue1","black"), alpha = .8)

```

## Was sind die Tweets mit den negativsten/positivsten Werten?

### CDU
```{r, echo=FALSE, message=FALSE, warning=FALSE}
token %>%
  filter(partei == "CDU") %>%
  arrange(Wert) %>%
    distinct(text, .keep_all = TRUE) %>%
  select(text, Wert) %>%
  .[1:5,] %>%
  htmlTable(align="l")
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
token %>%
  filter(partei == "CDU") %>%
  arrange(desc(Wert)) %>%
  distinct(text, .keep_all = TRUE) %>%
  select(text, Wert) %>%
  .[5:10,] %>%
  htmlTable(align="l")
```

### SPD
```{r, echo=FALSE, message=FALSE, warning=FALSE}
token %>%
  filter(partei == "SPD") %>%
  arrange(Wert) %>%
    distinct(text, .keep_all = TRUE) %>%
  select(text, Wert) %>%
  .[1:5,] %>%
  htmlTable(align="l")
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
token %>%
  filter(partei == "SPD") %>%
  arrange(desc(Wert)) %>%
  distinct(text, .keep_all = TRUE) %>%
  select(text, Wert) %>%
  .[1:5,] %>%
  htmlTable(align="l")
```

### FDP
```{r, echo=FALSE, message=FALSE, warning=FALSE}
token %>%
  filter(partei == "FDP") %>%
  arrange(Wert) %>%
    distinct(text, .keep_all = TRUE) %>%
  select(text, Wert) %>%
  .[1:5,] %>%
  htmlTable(align="l")
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
token %>%
  filter(partei == "FDP") %>%
  arrange(desc(Wert)) %>%
  distinct(text, .keep_all = TRUE) %>%
  select(text, Wert) %>%
  .[1:5,] %>%
  htmlTable(align="l")
```

### AfD
```{r, echo=FALSE, message=FALSE, warning=FALSE}
token %>%
  filter(partei == "AfD") %>%
  arrange(Wert) %>%
    distinct(text, .keep_all = TRUE) %>%
  select(text, Wert) %>%
  .[1:5,] %>%
  htmlTable(align="l")
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
token %>%
  filter(partei == "AfD") %>%
  arrange(desc(Wert)) %>%
  distinct(text, .keep_all = TRUE) %>%
  select(text, Wert) %>%
  .[1:5,] %>%
  htmlTable(align="l")
```

### Die Grünen
```{r, echo=FALSE, message=FALSE, warning=FALSE}
token %>%
  filter(partei == "Die Grünen") %>%
  arrange(Wert) %>%
    distinct(text, .keep_all = TRUE) %>%
  select(text, Wert) %>%
  .[1:5,] %>%
  htmlTable(align="l")
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
token %>%
  filter(partei == "Die Grünen") %>%
  arrange(desc(Wert)) %>%
  distinct(text, .keep_all = TRUE) %>%
  select(text, Wert) %>%
  .[1:5,] %>%
  htmlTable(align="l")
```

### DIE LINKE
```{r, echo=FALSE, message=FALSE, warning=FALSE}
token %>%
  filter(partei == "DIE LINKE") %>%
  arrange(Wert) %>%
    distinct(text, .keep_all = TRUE) %>%
  select(text, Wert) %>%
  .[1:5,] %>%
  htmlTable(align="l")
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
token %>%
  filter(partei == "DIE LINKE") %>%
  arrange(desc(Wert)) %>%
  distinct(text, .keep_all = TRUE) %>%
  select(text, Wert) %>%
  .[1:5,] %>%
  htmlTable(align="l")
```
### Tweets ohne explizite Partei-Nennung
```{r, echo=FALSE, message=FALSE, warning=FALSE}
token %>%
  filter(partei == "None") %>%
  arrange(Wert) %>%
    distinct(text, .keep_all = TRUE) %>%
  select(text, Wert) %>%
  .[1:5,] %>%
  htmlTable(align="l")
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
token %>%
  filter(partei == "None") %>%
  arrange(desc(Wert)) %>%
  distinct(text, .keep_all = TRUE) %>%
  select(text, Wert) %>%
  .[1:5,] %>%
  htmlTable(align="l")
```